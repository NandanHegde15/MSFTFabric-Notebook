{"cells":[{"cell_type":"code","source":["# install semantic-link-labs\n","%pip install semantic-link-labs"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"41423428-c99a-474f-b5bd-9c36e0026b31"},{"cell_type":"code","source":["Param_ConnectionId= \"\"\n","Param_ConnectionName= \"\""],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"tags":["parameters"]},"id":"13818cfa-086c-45b2-94e1-91c50f9b81f0"},{"cell_type":"code","source":["import sempy.fabric as fabric\n","import sempy_labs as labs\n","import pandas as pd\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import StructType, StructField, StringType\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","\n","\n","\n","# ---------------------------\n","# Get List of all workspaces\n","# ---------------------------\n","df_workspaces = fabric.list_workspaces().query('Type != \"AdminInsights\"')\n","\n","print(f\"Found {len(df_workspaces)} workspaces\")\n","\n","# ---------------------------\n","# Get all items from these workspaces\n","# ---------------------------\n","df_items = pd.concat(\n","    [fabric.list_items(workspace=ws_id) for ws_id in df_workspaces.Id],\n","    ignore_index=True\n",")\n","\n","print(f\"Found {len(df_items)} items across all workspaces.\")\n","\n","#df_connections_items = df_items[df_items[\"Type\"].isin(['Dataflow', 'DataPipeline', 'SemanticModel','Lakehouse','CopyJob'])] # Only these Item Types leverage Connections\n","df_connections_items = df_items[df_items[\"Type\"].isin(['SemanticModel','Dataflow'])] \n","df_connections_items = df_connections_items.merge(df_workspaces[[\"Id\", \"Name\"]], left_on=\"Workspace Id\", right_on=\"Id\", suffixes=('', '_Workspace'))\n","\n","# ---------------------------\n","#Iterate items and fetch connection details\n","# ---------------------------\n","connection_records = []\n","\n","for _, item in df_connections_items.iterrows():\n","    try:\n","        connections_df = labs.list_item_connections(\n","            item_name=item[\"Display Name\"],\n","            item_type=item.Type,\n","            workspace=item[\"Workspace Id\"]\n","        )\n","\n","        if not connections_df.empty:\n","            for _, conn in connections_df.iterrows():\n","                connection_records.append({\n","                    \"WorkspaceId\": item[\"Workspace Id\"],\n","                    \"WorkspaceName\": item[\"Name\"],\n","                    \"ItemName\": item[\"Display Name\"],\n","                    \"ItemType\": item.Type,\n","                    \"ConnectionId\": conn.get(\"Connection Id\", None),\n","                    \"ConnectionName\": conn.get(\"Connection Name\", None),\n","                    \"ConnectionType\": conn.get(\"Connection Type\", None)\n","                })\n","\n","    except Exception as e:\n","        print(f\"Failed to get connections for {item['Display Name']} of {item.Type} from Workspace {item['Name']}\")\n","\n","# ---------------------------\n","# Convert to DataFrame and display\n","# ---------------------------\n","df_connections = pd.DataFrame(connection_records)\n","\n","# ---------------------------\n","# Filter based on Parameter Value\n","# ---------------------------\n","if Param_ConnectionId.strip(): \n","    df_connections = df_connections[df_connections[\"ConnectionId\"] == Param_ConnectionId]\n","else:\n","    if Param_ConnectionName.strip():\n","        df_connections = df_connections[df_connections[\"ConnectionName\"] == Param_ConnectionName]\n","    else:\n","        df_connections = df_connections #Get all Connection Details\n","\n","print(f\"Total connections fetched: {len(df_connections['ConnectionId'].unique())}\")\n","\n","display(df_connections)\n","\n","# ---------------------------\n","# Create DAG using networkx\n","# ---------------------------\n","G = nx.DiGraph()\n","node_colors = {}\n","\n","for _, row in df_connections.iterrows():\n","    source_node = f\"{row['ItemName']} ({row['ItemType']}) ({row['WorkspaceName']})\"\n","    target_node = f\"{row['ConnectionName']} ({row['ConnectionId']}) ({row['ConnectionType']})\"\n","    \n","    G.add_edge(source_node, target_node)\n","    \n","    # Assign colors\n","    node_colors[source_node] = 'lightblue'   # sources in blue\n","    node_colors[target_node] = 'lightgreen'  # connections in green\n","\n","# ---------------------------\n","#Plot the DAG\n","# ---------------------------\n","\n","plt.figure(figsize=(14, 10))\n","pos = nx.spring_layout(G, k=0.6, seed=42)\n","\n","# ---------------------------\n","# Draw nodes with custom colors\n","# ---------------------------\n","\n","nx.draw(\n","    G, pos,\n","    with_labels=True,\n","    node_color=[node_colors[node] for node in G.nodes()],\n","    node_size=3000,\n","    font_size=8,\n","    font_weight='bold',\n","    arrows=True\n",")\n","\n","plt.title(\"Connection Dependency DAG\", fontsize=16)\n","plt.axis('off')\n","plt.show()\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"4d4b76fd-bf9e-44de-b9be-8b6f32c42c87"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}